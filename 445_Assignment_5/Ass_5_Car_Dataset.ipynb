{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xjg-hU8Xz0G8"
      },
      "outputs": [],
      "source": [
        "# Swapnil Saha Shawon (2022533042)\n",
        "# Tamanna Rahman (2021450642)\n",
        "# Syeda Mashiat Tabassum (2031356642)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Car Dataset**"
      ],
      "metadata": {
        "id": "1cHKVysz2hGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#include libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#load data and checking contents\n",
        "data = pd.read_csv(\"car.data.csv\")\n",
        "print(data)\n",
        "\n",
        "#check for null values\n",
        "print(\"\\nChecking NULL values:\\n\",data.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6euOoj9c2gcR",
        "outputId": "8a009940-f8d4-4b71-9656-6e9ae3dc21dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     buying  maint  doors persons lug_boot safety  class\n",
            "0     vhigh  vhigh      2       2    small    low  unacc\n",
            "1     vhigh  vhigh      2       2    small    med  unacc\n",
            "2     vhigh  vhigh      2       2    small   high  unacc\n",
            "3     vhigh  vhigh      2       2      med    low  unacc\n",
            "4     vhigh  vhigh      2       2      med    med  unacc\n",
            "...     ...    ...    ...     ...      ...    ...    ...\n",
            "1723    low    low  5more    more      med    med   good\n",
            "1724    low    low  5more    more      med   high  vgood\n",
            "1725    low    low  5more    more      big    low  unacc\n",
            "1726    low    low  5more    more      big    med   good\n",
            "1727    low    low  5more    more      big   high  vgood\n",
            "\n",
            "[1728 rows x 7 columns]\n",
            "\n",
            "Checking NULL values:\n",
            " buying      0\n",
            "maint       0\n",
            "doors       0\n",
            "persons     0\n",
            "lug_boot    0\n",
            "safety      0\n",
            "class       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing data\n",
        "categorical_cols = data.select_dtypes(include=['object']).columns.tolist()\n",
        "print(\"Categorical Columns:\", categorical_cols)\n",
        "print(\"\\n\")\n",
        "\n",
        "#label encoding features\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "labelEncoder = LabelEncoder()\n",
        "\n",
        "for col in categorical_cols:\n",
        "  data[col] = labelEncoder.fit_transform(data[col])\n",
        "\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uq7N4OUa2p9_",
        "outputId": "8969d0b9-1d00-47de-e49b-c3e12b82e166"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categorical Columns: ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']\n",
            "\n",
            "\n",
            "      buying  maint  doors  persons  lug_boot  safety  class\n",
            "0          3      3      0        0         2       1      2\n",
            "1          3      3      0        0         2       2      2\n",
            "2          3      3      0        0         2       0      2\n",
            "3          3      3      0        0         1       1      2\n",
            "4          3      3      0        0         1       2      2\n",
            "...      ...    ...    ...      ...       ...     ...    ...\n",
            "1723       1      1      3        2         1       2      1\n",
            "1724       1      1      3        2         1       0      3\n",
            "1725       1      1      3        2         0       1      2\n",
            "1726       1      1      3        2         0       2      1\n",
            "1727       1      1      3        2         0       0      3\n",
            "\n",
            "[1728 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#selecting target variable and features\n",
        "X = data.drop('class', axis = 1)\n",
        "y = data['class']\n",
        "\n",
        "#splitting data for training, validating and testing\n",
        "X_train = X.iloc[:1209]\n",
        "X_validation = X.iloc[1209:1468]\n",
        "X_test = X.iloc[1468:]\n",
        "print(X_validation)\n",
        "y_train = y.iloc[:1209]\n",
        "y_validation = y.iloc[1209:1468]\n",
        "y_test = y.iloc[1468:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soFx8OtG2spf",
        "outputId": "93be28cf-ae0d-4511-c2d2-ce54410f63a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      buying  maint  doors  persons  lug_boot  safety\n",
            "1209       2      1      0        2         1       1\n",
            "1210       2      1      0        2         1       2\n",
            "1211       2      1      0        2         1       0\n",
            "1212       2      1      0        2         0       1\n",
            "1213       2      1      0        2         0       2\n",
            "...      ...    ...    ...      ...       ...     ...\n",
            "1463       1      0      2        0         1       0\n",
            "1464       1      0      2        0         0       1\n",
            "1465       1      0      2        0         0       2\n",
            "1466       1      0      2        0         0       0\n",
            "1467       1      0      2        1         2       1\n",
            "\n",
            "[259 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Evaluation Metrics**"
      ],
      "metadata": {
        "id": "zeCqw4VK2uxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy\n",
        "def calc_accuracy(y_true, y_pred):\n",
        "  correct = 0\n",
        "  total = len(y_true)\n",
        "\n",
        "  for true_label, predicted_label in zip(y_true, y_pred):\n",
        "    if true_label == predicted_label:\n",
        "      correct += 1\n",
        "\n",
        "  accuracy = correct / total\n",
        "  return accuracy\n",
        "\n",
        "#Confusion Matrix\n",
        "def confusion_matrix(y_true, y_pred):\n",
        "  TN, TP, FN, FP = 0, 0, 0, 0\n",
        "\n",
        "  for true_label, predicted_label in zip(y_true, y_pred):\n",
        "    if true_label == 0 and predicted_label == 0:\n",
        "      TN += 1\n",
        "    elif true_label == 0 and predicted_label == 1:\n",
        "      FP += 1\n",
        "    elif true_label == 1 and predicted_label == 0:\n",
        "      FN += 1\n",
        "    elif true_label == 1 and predicted_label == 1:\n",
        "      TP += 1\n",
        "\n",
        "  return (TN, TP, FN, FP)\n",
        "\n",
        "#Average Precision\n",
        "def avg_precision(y_true, y_pred):\n",
        "  data = list(zip(y_true, y_pred))\n",
        "  data.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "  # Initialize variables\n",
        "  num_positives = sum(y_true)\n",
        "  num_examples = len(y_true)\n",
        "  true_positives = 0\n",
        "  precision_sum = 0\n",
        "  recall_sum = 0\n",
        "\n",
        "  # Calculate precision and recall at each threshold\n",
        "  for i in range(num_examples):\n",
        "    if data[i][0] == 1:\n",
        "      true_positives += 1\n",
        "      precision = true_positives / (i + 1)\n",
        "      recall = true_positives / num_positives\n",
        "      precision_sum += precision\n",
        "      recall_sum += recall\n",
        "\n",
        "  # Calculate Average Precision (AP) using the precision-recall curve\n",
        "  if num_positives == 0:\n",
        "    average_precision = 0\n",
        "  else:\n",
        "    average_precision = precision_sum / num_positives\n",
        "\n",
        "  return average_precision\n",
        "\n",
        "\n",
        "#Average Recall\n",
        "def avg_recall(y_true, y_pred):\n",
        "  total_positives = sum(y_true)  # Total number of positive samples\n",
        "  thresholds = sorted(set(y_pred), reverse=True)  # Unique sorted thresholds\n",
        "\n",
        "  recall_values = []\n",
        "  for threshold in thresholds:\n",
        "    y_pred_thresholded = [1 if pred >= threshold else 0 for pred in y_pred]\n",
        "    true_positives = sum([1 for true, pred in zip(y_true, y_pred_thresholded) if true == 1 and pred == 1])\n",
        "    recall = true_positives / total_positives\n",
        "    recall_values.append(recall)\n",
        "\n",
        "  average_recall = sum(recall_values) / len(recall_values)\n",
        "\n",
        "  return average_recall\n",
        "\n",
        "#Average F1-Score\n",
        "def avg_f1(y_true, y_pred):\n",
        "  total_positives = sum(y_true)  # Total number of positive samples\n",
        "  thresholds = sorted(set(y_pred), reverse=True)  # Unique sorted thresholds\n",
        "\n",
        "  f1_scores = []\n",
        "  for threshold in thresholds:\n",
        "    y_pred_thresholded = [1 if pred >= threshold else 0 for pred in y_pred]\n",
        "\n",
        "  # Calculate precision and recall\n",
        "  true_positives = sum([1 for true, pred in zip(y_true, y_pred_thresholded) if true == 1 and pred == 1])\n",
        "  predicted_positives = sum(y_pred_thresholded)\n",
        "\n",
        "  if predicted_positives == 0:\n",
        "    precision = 0.0\n",
        "  else:\n",
        "    precision = true_positives / predicted_positives\n",
        "\n",
        "  recall = true_positives / total_positives\n",
        "\n",
        "  # Calculate F1-score\n",
        "  if precision + recall == 0:\n",
        "    f1 = 0.0\n",
        "  else:\n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "  f1_scores.append(f1)\n",
        "\n",
        "  average_f1_score = sum(f1_scores) / len(f1_scores)\n",
        "\n",
        "  return average_f1_score"
      ],
      "metadata": {
        "id": "nMZ-s5CW2xio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ZeroR Classifier**"
      ],
      "metadata": {
        "id": "0UQ4tYgf22Cq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build ZeroR Classifier\n",
        "from collections import Counter\n",
        "\n",
        "class ZeroR:\n",
        "    def __init__(self):\n",
        "        self.majority_class = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Find the majority class\n",
        "        self.majority_class = Counter(y).most_common(1)[0][0]\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Return the majority class for all instances\n",
        "        return [self.majority_class] * len(X)\n",
        "\n",
        "\n",
        "# Initialize the ZeroR model\n",
        "zr = ZeroR()\n",
        "\n",
        "# Train the model\n",
        "zr.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "2rDO3C9V25Mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating with Training set\n",
        "y_pred = zr.predict(X_train)\n",
        "\n",
        "acc = calc_accuracy(y_train, y_pred)\n",
        "print(\"Accuracy: \", acc)\n",
        "ap = avg_precision(y_train, y_pred)\n",
        "print(\"Average Precision: \", ap)\n",
        "ar = avg_recall(y_train, y_pred)\n",
        "print(\"Average Recall: \", ar)\n",
        "af = avg_f1(y_train, y_pred)\n",
        "print(\"Average F1-Score: \", af)\n",
        "TN, TP, FN, FP = confusion_matrix(y_train, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(f\"TN: {TN}   FP: {FP}\")\n",
        "print(f\"FN: {FN}   TP: {TP}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtXilD-X6CBL",
        "outputId": "7ed4956e-1caa-4b08-8a73-cc51ae118988"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.7485525227460711\n",
            "Average Precision:  2.6875850566252678e-06\n",
            "Average Recall:  0.0016172506738544475\n",
            "Average F1-Score:  0.0019582245430809398\n",
            "Confusion Matrix:\n",
            "TN: 0   FP: 0\n",
            "FN: 0   TP: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating with Validation set\n",
        "y_pred = zr.predict(X_validation)\n",
        "\n",
        "acc = calc_accuracy(y_validation, y_pred)\n",
        "print(\"Accuracy: \", acc)\n",
        "ap = avg_precision(y_validation, y_pred)\n",
        "print(\"Average Precision: \", ap)\n",
        "ar = avg_recall(y_validation, y_pred)\n",
        "print(\"Average Recall: \", ar)\n",
        "af = avg_f1(y_validation, y_pred)\n",
        "print(\"Average F1-Score: \", af)\n",
        "TN, TP, FN, FP = confusion_matrix(y_validation, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(f\"TN: {TN}   FP: {FP}\")\n",
        "print(f\"FN: {FN}   TP: {TP}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeY82RFmknyb",
        "outputId": "8863faec-aec5-42a2-be48-a26ff502184d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.6216216216216216\n",
            "Average Precision:  0.011895452912296833\n",
            "Average Recall:  0.05089058524173028\n",
            "Average F1-Score:  0.06134969325153374\n",
            "Confusion Matrix:\n",
            "TN: 0   FP: 0\n",
            "FN: 0   TP: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating with Testing set\n",
        "y_pred = zr.predict(X_test)\n",
        "\n",
        "acc = calc_accuracy(y_test, y_pred)\n",
        "print(\"Accuracy: \", acc)\n",
        "ap = avg_precision(y_test, y_pred)\n",
        "print(\"Average Precision: \", ap)\n",
        "ar = avg_recall(y_test, y_pred)\n",
        "print(\"Average Recall: \", ar)\n",
        "af = avg_f1(y_test, y_pred)\n",
        "print(\"Average F1-Score: \", af)\n",
        "TN, TP, FN, FP = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(f\"TN: {TN}   FP: {FP}\")\n",
        "print(f\"FN: {FN}   TP: {TP}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oCpDHzykxZ6",
        "outputId": "8f148b01-e703-4afe-c697-78b66ac2a25c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5538461538461539\n",
            "Average Precision:  0.014082758306997751\n",
            "Average Recall:  0.10550458715596331\n",
            "Average F1-Score:  0.13218390804597702\n",
            "Confusion Matrix:\n",
            "TN: 0   FP: 0\n",
            "FN: 0   TP: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **OneR Classifier**"
      ],
      "metadata": {
        "id": "OsbUU1UQVZJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "class OneRClassifier:\n",
        "    def __init__(self):\n",
        "        self.best_attribute = None\n",
        "        self.mapping = {}\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        if len(X) != len(y):\n",
        "            raise ValueError(\"Number of samples in X and y must be the same\")\n",
        "\n",
        "        min_error = float('inf')\n",
        "\n",
        "        for i in range(len(X[0])):\n",
        "            attribute_values = defaultdict(list)\n",
        "            for j in range(len(X)):\n",
        "                attribute_values[X[j][i]].append(y[j])\n",
        "\n",
        "            error = sum(len(attribute_values[val]) - max(self.count_classes(attribute_values[val]).values()) for val in attribute_values)\n",
        "\n",
        "            if error < min_error:\n",
        "                min_error = error\n",
        "                self.best_attribute = i\n",
        "                self.mapping = {val: max(self.count_classes(attribute_values[val]), key=self.count_classes(attribute_values[val]).get) for val in attribute_values}\n",
        "\n",
        "    def predict(self, X):\n",
        "        if self.best_attribute is None:\n",
        "            raise ValueError(\"The model has not been trained yet. Call fit() before predict()\")\n",
        "\n",
        "        predictions = []\n",
        "        for sample in X:\n",
        "            predictions.append(self.mapping[sample[self.best_attribute]])\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    def count_classes(self, classes):\n",
        "        counts = defaultdict(int)\n",
        "        for c in classes:\n",
        "            counts[c] += 1\n",
        "        return counts\n",
        "\n",
        "# Initialize the OneR model\n",
        "oner_model = OneRClassifier()\n",
        "\n",
        "y_train_bool = [bool(val) for val in y_train]\n",
        "\n",
        "# Train the model\n",
        "oner_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "predictions = oner_model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "5BSMWmwRVol1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "ffc83021-7968-4b00-9a73-cf781844425f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3653\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-2db717e822eb>\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0moner_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# Make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-2db717e822eb>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mmin_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mattribute_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3761\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3762\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3763\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3655\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3656\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3657\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **K-Nearest-Neighbor Classifiers**"
      ],
      "metadata": {
        "id": "-GjAlGtS1GjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the dataset\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "#Define the KNN Classifier\n",
        "knn_classifier = KNeighborsClassifier()\n",
        "\n",
        "knn = knn_classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "22WHG_eb1SXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Validating the model using training set\n",
        "y_pred = knn.predict(X_train)\n",
        "\n",
        "acc = calc_accuracy(y_train, y_pred)\n",
        "print(\"Accuracy: \", acc)\n",
        "ap = avg_precision(y_train, y_pred)\n",
        "print(\"Average Precision: \", ap)\n",
        "ar = avg_recall(y_train, y_pred)\n",
        "print(\"Average Recall: \", ar)\n",
        "af = avg_f1(y_train, y_pred)\n",
        "print(\"Average F1-Score: \", af)\n",
        "TN, TP, FN, FP = confusion_matrix(y_train, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(f\"TN: {TN}   FP: {FP}\")\n",
        "print(f\"FN: {FN}   TP: {TP}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5_OmkGC132j",
        "outputId": "d0a44583-8b71-4f37-8450-799bea7cb4b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9487179487179487\n",
            "Average Precision:  3.024655875698897e-06\n",
            "Average Recall:  0.0006738544474393531\n",
            "Average F1-Score:  0.0019582245430809398\n",
            "Confusion Matrix:\n",
            "TN: 238   FP: 0\n",
            "FN: 1   TP: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Validating the model using validation set\n",
        "y_pred = knn.predict(X_validation)\n",
        "\n",
        "acc = calc_accuracy(y_validation, y_pred)\n",
        "print(\"Accuracy: \", acc)\n",
        "ap = avg_precision(y_validation, y_pred)\n",
        "print(\"Average Precision: \", ap)\n",
        "ar = avg_recall(y_validation, y_pred)\n",
        "print(\"Average Recall: \", ar)\n",
        "af = avg_f1(y_validation, y_pred)\n",
        "print(\"Average F1-Score: \", af)\n",
        "TN, TP, FN, FP = confusion_matrix(y_validation, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(f\"TN: {TN}   FP: {FP}\")\n",
        "print(f\"FN: {FN}   TP: {TP}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cViD_awn2RGh",
        "outputId": "79ccee53-1e5a-4c66-faa7-c1ae3cd8b94d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.7451737451737451\n",
            "Average Precision:  0.0025423228051409076\n",
            "Average Recall:  0.02544529262086514\n",
            "Average F1-Score:  0.06134969325153374\n",
            "Confusion Matrix:\n",
            "TN: 32   FP: 0\n",
            "FN: 20   TP: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Validating\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the hyperparameter grid for grid search\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan']\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV with cross-validation (e.g., 5-fold)\n",
        "grid_search = GridSearchCV(knn_classifier, param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit GridSearchCV on the combined training and validation sets\n",
        "X_train_new = X.iloc[:74]\n",
        "y_train_new = y.iloc[:74]\n",
        "grid_search.fit(X_train_new, y_train_new)\n",
        "\n",
        "# Get the best model on the test set\n",
        "best_knn_model = grid_search.best_estimator_\n",
        "\n",
        "print(best_knn_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_NrYY903e3W",
        "outputId": "8905078c-5e5b-4c1d-bd0a-80edcdb1bbab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNeighborsClassifier(metric='euclidean', n_neighbors=3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing best model using test set\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "acc = calc_accuracy(y_test, y_pred)\n",
        "print(\"Accuracy: \", acc)\n",
        "ap = avg_precision(y_test, y_pred)\n",
        "print(\"Average Precision: \", ap)\n",
        "ar = avg_recall(y_test, y_pred)\n",
        "print(\"Average Recall: \", ar)\n",
        "af = avg_f1(y_test, y_pred)\n",
        "print(\"Average F1-Score: \", af)\n",
        "TN, TP, FN, FP = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(f\"TN: {TN}   FP: {FP}\")\n",
        "print(f\"FN: {FN}   TP: {TP}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ccKCxMR2raB",
        "outputId": "7623d107-b545-4cc0-8625-909d668cf587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.6\n",
            "Average Precision:  0.010657299012418442\n",
            "Average Recall:  0.05504587155963303\n",
            "Average F1-Score:  0.13218390804597702\n",
            "Confusion Matrix:\n",
            "TN: 12   FP: 0\n",
            "FN: 44   TP: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Naive Bayesian Classifier**"
      ],
      "metadata": {
        "id": "_z2CaTSn4yVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the dataset\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "nb_classifier = GaussianNB()\n",
        "nb = nb_classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "QJJGZgOU43eJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Validating the model using training set\n",
        "y_pred = nb.predict(X_train)\n",
        "\n",
        "acc = calc_accuracy(y_train, y_pred)\n",
        "print(\"Accuracy: \", acc)\n",
        "ap = avg_precision(y_train, y_pred)\n",
        "print(\"Average Precision: \", ap)\n",
        "ar = avg_recall(y_train, y_pred)\n",
        "print(\"Average Recall: \", ar)\n",
        "af = avg_f1(y_train, y_pred)\n",
        "print(\"Average F1-Score: \", af)\n",
        "TN, TP, FN, FP = confusion_matrix(y_train, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(f\"TN: {TN}   FP: {FP}\")\n",
        "print(f\"FN: {FN}   TP: {TP}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bee5f806-47a8-4926-fe0c-d18d503f6105",
        "id": "jsOuL7kD5AUf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.7741935483870968\n",
            "Average Precision:  2.9824899027571626e-06\n",
            "Average Recall:  0.0008086253369272237\n",
            "Average F1-Score:  0.0019582245430809398\n",
            "Confusion Matrix:\n",
            "TN: 85   FP: 2\n",
            "FN: 0   TP: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Validating the model using validation set\n",
        "y_pred = nb.predict(X_validation)\n",
        "\n",
        "acc = calc_accuracy(y_validation, y_pred)\n",
        "print(\"Accuracy: \", acc)\n",
        "ap = avg_precision(y_validation, y_pred)\n",
        "print(\"Average Precision: \", ap)\n",
        "ar = avg_recall(y_validation, y_pred)\n",
        "print(\"Average Recall: \", ar)\n",
        "af = avg_f1(y_validation, y_pred)\n",
        "print(\"Average F1-Score: \", af)\n",
        "TN, TP, FN, FP = confusion_matrix(y_validation, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(f\"TN: {TN}   FP: {FP}\")\n",
        "print(f\"FN: {FN}   TP: {TP}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da64b8f6-0fae-4e27-db02-fc1c8815c197",
        "id": "-r7kAG5u5AUg"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.6486486486486487\n",
            "Average Precision:  0.014052520714109732\n",
            "Average Recall:  0.037319762510602206\n",
            "Average F1-Score:  0.06134969325153374\n",
            "Confusion Matrix:\n",
            "TN: 8   FP: 0\n",
            "FN: 4   TP: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing best model using test set\n",
        "y_pred = nb.predict(X_test)\n",
        "\n",
        "acc = calc_accuracy(y_test, y_pred)\n",
        "print(\"Accuracy: \", acc)\n",
        "ap = avg_precision(y_test, y_pred)\n",
        "print(\"Average Precision: \", ap)\n",
        "ar = avg_recall(y_test, y_pred)\n",
        "print(\"Average Recall: \", ar)\n",
        "af = avg_f1(y_test, y_pred)\n",
        "print(\"Average F1-Score: \", af)\n",
        "TN, TP, FN, FP = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(f\"TN: {TN}   FP: {FP}\")\n",
        "print(f\"FN: {FN}   TP: {TP}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5e19e8d-466a-4b63-aeaa-b46df2978fc3",
        "id": "tRrkaV-Y5AUg"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5307692307692308\n",
            "Average Precision:  0.013981771841030336\n",
            "Average Recall:  0.0871559633027523\n",
            "Average F1-Score:  0.13218390804597702\n",
            "Confusion Matrix:\n",
            "TN: 5   FP: 0\n",
            "FN: 16   TP: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Support vector machine (SVM)**"
      ],
      "metadata": {
        "id": "Cki6DzcT9DnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the dataset\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#Define the SVC Classifier\n",
        "svm_classifier = SVC()\n",
        "\n",
        "svm = svm_classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "SWLbcat69DnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Validating the model using training set\n",
        "y_pred = svm.predict(X_train)\n",
        "\n",
        "acc = calc_accuracy(y_train, y_pred)\n",
        "print(\"Accuracy: \", acc)\n",
        "ap = avg_precision(y_train, y_pred)\n",
        "print(\"Average Precision: \", ap)\n",
        "ar = avg_recall(y_train, y_pred)\n",
        "print(\"Average Recall: \", ar)\n",
        "af = avg_f1(y_train, y_pred)\n",
        "print(\"Average F1-Score: \", af)\n",
        "TN, TP, FN, FP = confusion_matrix(y_train, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(f\"TN: {TN}   FP: {FP}\")\n",
        "print(f\"FN: {FN}   TP: {TP}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0d82c06-0816-4f6b-bdad-2ed0a66cddac",
        "id": "wuuWgyQQ9DnW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9330024813895782\n",
            "Average Precision:  2.681267684164944e-06\n",
            "Average Recall:  0.0008086253369272237\n",
            "Average F1-Score:  0.0019582245430809398\n",
            "Confusion Matrix:\n",
            "TN: 234   FP: 0\n",
            "FN: 3   TP: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Validating the model using validation set\n",
        "y_pred = svm.predict(X_validation)\n",
        "\n",
        "acc = calc_accuracy(y_validation, y_pred)\n",
        "print(\"Accuracy: \", acc)\n",
        "ap = avg_precision(y_validation, y_pred)\n",
        "print(\"Average Precision: \", ap)\n",
        "ar = avg_recall(y_validation, y_pred)\n",
        "print(\"Average Recall: \", ar)\n",
        "af = avg_f1(y_validation, y_pred)\n",
        "print(\"Average F1-Score: \", af)\n",
        "TN, TP, FN, FP = confusion_matrix(y_validation, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(f\"TN: {TN}   FP: {FP}\")\n",
        "print(f\"FN: {FN}   TP: {TP}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e54e750-2151-4572-ec33-cf17b9be6c13",
        "id": "R1dY4rRq9DnW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.6756756756756757\n",
            "Average Precision:  0.002482398848584853\n",
            "Average Recall:  0.02544529262086514\n",
            "Average F1-Score:  0.06134969325153374\n",
            "Confusion Matrix:\n",
            "TN: 23   FP: 0\n",
            "FN: 20   TP: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing best model using test set\n",
        "y_pred = svm.predict(X_test)\n",
        "\n",
        "acc = calc_accuracy(y_test, y_pred)\n",
        "print(\"Accuracy: \", acc)\n",
        "ap = avg_precision(y_test, y_pred)\n",
        "print(\"Average Precision: \", ap)\n",
        "ar = avg_recall(y_test, y_pred)\n",
        "print(\"Average Recall: \", ar)\n",
        "af = avg_f1(y_test, y_pred)\n",
        "print(\"Average F1-Score: \", af)\n",
        "TN, TP, FN, FP = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(f\"TN: {TN}   FP: {FP}\")\n",
        "print(f\"FN: {FN}   TP: {TP}\")"
      ],
      "metadata": {
        "id": "hlAxhANp9DnX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bacad618-5325-4f34-c3da-8d24b626b486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5538461538461539\n",
            "Average Precision:  0.01091128877792928\n",
            "Average Recall:  0.052752293577981654\n",
            "Average F1-Score:  0.13218390804597702\n",
            "Confusion Matrix:\n",
            "TN: 14   FP: 0\n",
            "FN: 46   TP: 0\n"
          ]
        }
      ]
    }
  ]
}