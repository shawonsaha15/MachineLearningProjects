{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Brain Cancer Dataset**"
      ],
      "metadata": {
        "id": "8Y9DWKUXp4Ak"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ocj1vSQFpKjC",
        "outputId": "1abe6013-8b5a-4f4e-c43f-134152b8537b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Unnamed: 0     sex   diagnosis             loc  ki    gtv  status\n",
            "0            1  Female  Meningioma  Infratentorial  90   6.11       0\n",
            "1            2    Male   HG glioma  Supratentorial  90  19.35       1\n",
            "2            3  Female  Meningioma  Infratentorial  70   7.95       0\n",
            "3            4  Female   LG glioma  Supratentorial  80   7.61       1\n",
            "4            5    Male   HG glioma  Supratentorial  90   5.06       1\n",
            "..         ...     ...         ...             ...  ..    ...     ...\n",
            "83          84    Male   HG glioma  Supratentorial  80   0.16       1\n",
            "84          85    Male   HG glioma  Supratentorial  80  19.81       1\n",
            "85          86    Male  Meningioma  Supratentorial  90   2.50       0\n",
            "86          87    Male  Meningioma  Supratentorial  90   2.02       0\n",
            "87          88    Male       Other  Infratentorial  80   0.11       0\n",
            "\n",
            "[88 rows x 7 columns]\n",
            "\n",
            "Checking NULL values:\n",
            " Unnamed: 0    0\n",
            "sex           0\n",
            "diagnosis     1\n",
            "loc           0\n",
            "ki            0\n",
            "gtv           0\n",
            "status        0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#include libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#load data and checking contents\n",
        "data = pd.read_csv(\"DT-BrainCancer.csv\")\n",
        "print(data)\n",
        "\n",
        "#check for null values\n",
        "print(\"\\nChecking NULL values:\\n\",data.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing data\n",
        "categorical_cols = data.select_dtypes(include=['object']).columns.tolist()\n",
        "print(\"Categorical Columns:\", categorical_cols)\n",
        "print(\"\\n\")\n",
        "\n",
        "data = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhG9ohs9pTk7",
        "outputId": "869971e1-09f6-43b5-e02d-ecfab5967792"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categorical Columns: ['sex', 'diagnosis', 'loc']\n",
            "\n",
            "\n",
            "    Unnamed: 0  ki    gtv  status  sex_Male  diagnosis_LG glioma  \\\n",
            "0            1  90   6.11       0     False                False   \n",
            "1            2  90  19.35       1      True                False   \n",
            "2            3  70   7.95       0     False                False   \n",
            "3            4  80   7.61       1     False                 True   \n",
            "4            5  90   5.06       1      True                False   \n",
            "..         ...  ..    ...     ...       ...                  ...   \n",
            "83          84  80   0.16       1      True                False   \n",
            "84          85  80  19.81       1      True                False   \n",
            "85          86  90   2.50       0      True                False   \n",
            "86          87  90   2.02       0      True                False   \n",
            "87          88  80   0.11       0      True                False   \n",
            "\n",
            "    diagnosis_Meningioma  diagnosis_Other  loc_Supratentorial  \n",
            "0                   True            False               False  \n",
            "1                  False            False                True  \n",
            "2                   True            False               False  \n",
            "3                  False            False                True  \n",
            "4                  False            False                True  \n",
            "..                   ...              ...                 ...  \n",
            "83                 False            False                True  \n",
            "84                 False            False                True  \n",
            "85                  True            False                True  \n",
            "86                  True            False                True  \n",
            "87                 False             True               False  \n",
            "\n",
            "[88 rows x 9 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#selecting target variable and features\n",
        "X = data.drop('status', axis = 1)\n",
        "y = data['status']\n",
        "\n",
        "#splitting data for training, validating and testing\n",
        "X_train = X.iloc[:61]\n",
        "X_validation = X.iloc[61:74]\n",
        "X_test = X.iloc[74:]"
      ],
      "metadata": {
        "id": "OoU6sa9CpYSa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Evaluation Metrics**"
      ],
      "metadata": {
        "id": "ofzYLRAdpats"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy\n",
        "def calc_accuracy(y_true, y_pred):\n",
        "  correct = 0\n",
        "  total = len(y_true)\n",
        "\n",
        "  for true_label, predicted_label in zip(y_true, y_pred):\n",
        "    if true_label == predicted_label:\n",
        "      correct += 1\n",
        "\n",
        "  accuracy = correct / total\n",
        "  return accuracy\n",
        "\n",
        "#Confusion Matrix\n",
        "def confusion_matrix(y_true, y_pred):\n",
        "  TN, TP, FN, FP = 0, 0, 0, 0\n",
        "\n",
        "  for true_label, predicted_label in zip(y_true, y_pred):\n",
        "    if true_label == 0 and predicted_label == 0:\n",
        "      TN += 1\n",
        "    elif true_label == 0 and predicted_label == 1:\n",
        "      FP += 1\n",
        "    elif true_label == 1 and predicted_label == 0:\n",
        "      FN += 1\n",
        "    elif true_label == 1 and predicted_label == 1:\n",
        "      TP += 1\n",
        "\n",
        "  return (TN, TP, FN, FP)\n",
        "\n",
        "#Average Precision\n",
        "def avg_precision(y_true, y_pred):\n",
        "  data = list(zip(y_true, y_pred))\n",
        "  data.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "  # Initialize variables\n",
        "  num_positives = sum(y_true)\n",
        "  num_examples = len(y_true)\n",
        "  true_positives = 0\n",
        "  precision_sum = 0\n",
        "  recall_sum = 0\n",
        "\n",
        "  # Calculate precision and recall at each threshold\n",
        "  for i in range(num_examples):\n",
        "    if data[i][0] == 1:\n",
        "      true_positives += 1\n",
        "      precision = true_positives / (i + 1)\n",
        "      recall = true_positives / num_positives\n",
        "      precision_sum += precision\n",
        "      recall_sum += recall\n",
        "\n",
        "  # Calculate Average Precision (AP) using the precision-recall curve\n",
        "  if num_positives == 0:\n",
        "    average_precision = 0\n",
        "  else:\n",
        "    average_precision = precision_sum / num_positives\n",
        "\n",
        "  return average_precision\n",
        "\n",
        "\n",
        "#Average Recall\n",
        "def avg_recall(y_true, y_pred):\n",
        "  total_positives = sum(y_true)  # Total number of positive samples\n",
        "  thresholds = sorted(set(y_pred), reverse=True)  # Unique sorted thresholds\n",
        "\n",
        "  recall_values = []\n",
        "  for threshold in thresholds:\n",
        "    y_pred_thresholded = [1 if pred >= threshold else 0 for pred in y_pred]\n",
        "    true_positives = sum([1 for true, pred in zip(y_true, y_pred_thresholded) if true == 1 and pred == 1])\n",
        "    recall = true_positives / total_positives\n",
        "    recall_values.append(recall)\n",
        "\n",
        "  average_recall = sum(recall_values) / len(recall_values)\n",
        "\n",
        "  return average_recall\n",
        "\n",
        "#Average F1-Score\n",
        "def avg_f1(y_true, y_pred):\n",
        "  total_positives = sum(y_true)  # Total number of positive samples\n",
        "  thresholds = sorted(set(y_pred), reverse=True)  # Unique sorted thresholds\n",
        "\n",
        "  f1_scores = []\n",
        "  for threshold in thresholds:\n",
        "    y_pred_thresholded = [1 if pred >= threshold else 0 for pred in y_pred]\n",
        "\n",
        "  # Calculate precision and recall\n",
        "  true_positives = sum([1 for true, pred in zip(y_true, y_pred_thresholded) if true == 1 and pred == 1])\n",
        "  predicted_positives = sum(y_pred_thresholded)\n",
        "\n",
        "  if predicted_positives == 0:\n",
        "    precision = 0.0\n",
        "  else:\n",
        "    precision = true_positives / predicted_positives\n",
        "\n",
        "  recall = true_positives / total_positives\n",
        "\n",
        "  # Calculate F1-score\n",
        "  if precision + recall == 0:\n",
        "    f1 = 0.0\n",
        "  else:\n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "  f1_scores.append(f1)\n",
        "\n",
        "  average_f1_score = sum(f1_scores) / len(f1_scores)\n",
        "\n",
        "  return average_f1_score"
      ],
      "metadata": {
        "id": "kOUn11L-pgaq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}