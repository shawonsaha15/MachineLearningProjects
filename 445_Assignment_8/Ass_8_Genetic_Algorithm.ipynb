{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uVlMg5iO7hbw"
      },
      "outputs": [],
      "source": [
        "# Swapnil Saha Shawon (2022533042)\n",
        "# Tamanna Rahman (2021450642)\n",
        "# Syeda Mashiat Tabassum (2031356642)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#include libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#load data and checking contents\n",
        "data = pd.read_csv(\"car.data.csv\")\n",
        "print(data)\n",
        "\n",
        "#check for null values\n",
        "print(\"\\nChecking NULL values:\\n\",data.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQFgMquI78tE",
        "outputId": "a6441dd0-bed7-48d0-956f-ad7ddbdcdeb9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     buying  maint  doors persons lug_boot safety  class\n",
            "0     vhigh  vhigh      2       2    small    low  unacc\n",
            "1     vhigh  vhigh      2       2    small    med  unacc\n",
            "2     vhigh  vhigh      2       2    small   high  unacc\n",
            "3     vhigh  vhigh      2       2      med    low  unacc\n",
            "4     vhigh  vhigh      2       2      med    med  unacc\n",
            "...     ...    ...    ...     ...      ...    ...    ...\n",
            "1723    low    low  5more    more      med    med   good\n",
            "1724    low    low  5more    more      med   high  vgood\n",
            "1725    low    low  5more    more      big    low  unacc\n",
            "1726    low    low  5more    more      big    med   good\n",
            "1727    low    low  5more    more      big   high  vgood\n",
            "\n",
            "[1728 rows x 7 columns]\n",
            "\n",
            "Checking NULL values:\n",
            " buying      0\n",
            "maint       0\n",
            "doors       0\n",
            "persons     0\n",
            "lug_boot    0\n",
            "safety      0\n",
            "class       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing data\n",
        "categorical_cols = data.select_dtypes(include=['object']).columns.tolist()\n",
        "print(\"Categorical Columns:\", categorical_cols)\n",
        "print(\"\\n\")\n",
        "\n",
        "#label encoding features\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "labelEncoder = LabelEncoder()\n",
        "\n",
        "for col in categorical_cols:\n",
        "  data[col] = labelEncoder.fit_transform(data[col])\n",
        "\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sp1bXUBc8U5p",
        "outputId": "a05ce987-e6a8-4bad-d707-4ce26bb2a3d7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categorical Columns: ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']\n",
            "\n",
            "\n",
            "      buying  maint  doors  persons  lug_boot  safety  class\n",
            "0          3      3      0        0         2       1      2\n",
            "1          3      3      0        0         2       2      2\n",
            "2          3      3      0        0         2       0      2\n",
            "3          3      3      0        0         1       1      2\n",
            "4          3      3      0        0         1       2      2\n",
            "...      ...    ...    ...      ...       ...     ...    ...\n",
            "1723       1      1      3        2         1       2      1\n",
            "1724       1      1      3        2         1       0      3\n",
            "1725       1      1      3        2         0       1      2\n",
            "1726       1      1      3        2         0       2      1\n",
            "1727       1      1      3        2         0       0      3\n",
            "\n",
            "[1728 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#selecting target variable and features\n",
        "X = data.drop('class', axis = 1)\n",
        "y = data['class']\n",
        "\n",
        "#splitting data for training, validating and testing\n",
        "X_train = X.iloc[:1209]\n",
        "X_validation = X.iloc[1209:1468]\n",
        "X_test = X.iloc[1468:]\n",
        "print(X_validation)\n",
        "y_train = y.iloc[:1209]\n",
        "y_validation = y.iloc[1209:1468]\n",
        "y_test = y.iloc[1468:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW6RTKpU8ava",
        "outputId": "83f19b1f-073a-4bc0-9e29-6a6533e344ec"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      buying  maint  doors  persons  lug_boot  safety\n",
            "1209       2      1      0        2         1       1\n",
            "1210       2      1      0        2         1       2\n",
            "1211       2      1      0        2         1       0\n",
            "1212       2      1      0        2         0       1\n",
            "1213       2      1      0        2         0       2\n",
            "...      ...    ...    ...      ...       ...     ...\n",
            "1463       1      0      2        0         1       0\n",
            "1464       1      0      2        0         0       1\n",
            "1465       1      0      2        0         0       2\n",
            "1466       1      0      2        0         0       0\n",
            "1467       1      0      2        1         2       1\n",
            "\n",
            "[259 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define the fitness function\n",
        "def fitness_function(params):\n",
        "    C, gamma = params\n",
        "    model = SVC(C=C, gamma=gamma)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_validation)\n",
        "    accuracy = accuracy_score(y_validation, y_pred)\n",
        "    return accuracy\n",
        "\n",
        "# Create the initial population\n",
        "def create_population(size, param_ranges):\n",
        "    population = []\n",
        "    for _ in range(size):\n",
        "        individual = [random.uniform(*param_ranges[param]) for param in param_ranges]\n",
        "        population.append(individual)\n",
        "    return population\n",
        "\n",
        "# Evaluate the population\n",
        "def evaluate_population(population):\n",
        "    fitness_scores = [fitness_function(individual) for individual in population]\n",
        "    return fitness_scores\n",
        "\n",
        "# Select parents for crossover\n",
        "def select_parents(population, fitness_scores, num_parents):\n",
        "    selected = random.choices(population, weights=fitness_scores, k=num_parents)\n",
        "    return selected\n",
        "\n",
        "# Crossover between parents to create offspring\n",
        "def crossover(parents, offspring_size):\n",
        "    offspring = []\n",
        "    for _ in range(offspring_size):\n",
        "        parent1 = random.choice(parents)\n",
        "        parent2 = random.choice(parents)\n",
        "        child = [(p1 + p2) / 2 for p1, p2 in zip(parent1, parent2)]\n",
        "        offspring.append(child)\n",
        "    return offspring\n",
        "\n",
        "# Mutate the offspring\n",
        "def mutate(offspring, mutation_rate, param_ranges):\n",
        "    for individual in offspring:\n",
        "        if random.random() < mutation_rate:\n",
        "            param_idx = random.randint(0, len(individual) - 1)\n",
        "            individual[param_idx] = random.uniform(*param_ranges[list(param_ranges.keys())[param_idx]])\n",
        "    return offspring\n",
        "\n",
        "# Genetic algorithm\n",
        "def genetic_algorithm(pop_size, num_generations, mutation_rate, param_ranges):\n",
        "    population = create_population(pop_size, param_ranges)\n",
        "    for generation in range(num_generations):\n",
        "        fitness_scores = evaluate_population(population)\n",
        "        parents = select_parents(population, fitness_scores, pop_size // 2)\n",
        "        offspring = crossover(parents, pop_size - len(parents))\n",
        "        offspring = mutate(offspring, mutation_rate, param_ranges)\n",
        "        population = parents + offspring\n",
        "        best_individual = max(population, key=fitness_function)\n",
        "        best_fitness = fitness_function(best_individual)\n",
        "        print(f'Generation {generation}: Best Fitness = {best_fitness}, Best Individual = {best_individual}')\n",
        "    return best_individual, best_fitness\n",
        "\n",
        "# Parameters\n",
        "population_size = 20\n",
        "num_generations = 50\n",
        "mutation_rate = 0.1\n",
        "param_ranges = {\n",
        "    'C': (0.1, 100),\n",
        "    'gamma': (0.001, 1)\n",
        "}\n",
        "\n",
        "# Run the genetic algorithm\n",
        "best_params, best_fitness = genetic_algorithm(population_size, num_generations,\n",
        "                                              mutation_rate, param_ranges)\n",
        "print(f'Best hyperparameters: C={best_params[0]}, gamma={best_params[1]}')\n",
        "print(f'Best validation accuracy: {best_fitness}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ay_MbGiOHnHu",
        "outputId": "7daf295d-e123-4456-c8ec-7613af187bd4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation 0: Best Fitness = 0.8996138996138996, Best Individual = [55.07307157685905, 0.19743550926536474]\n",
            "Generation 1: Best Fitness = 0.8996138996138996, Best Individual = [55.07307157685905, 0.19743550926536474]\n",
            "Generation 2: Best Fitness = 0.8996138996138996, Best Individual = [55.07307157685905, 0.19743550926536474]\n",
            "Generation 3: Best Fitness = 0.8996138996138996, Best Individual = [55.07307157685905, 0.19743550926536474]\n",
            "Generation 4: Best Fitness = 0.8803088803088803, Best Individual = [35.03470560631848, 0.608863533541033]\n",
            "Generation 5: Best Fitness = 0.8803088803088803, Best Individual = [49.06892844654687, 0.5502450691821166]\n",
            "Generation 6: Best Fitness = 0.8996138996138996, Best Individual = [39.049745461276586, 0.15768639041768534]\n",
            "Generation 7: Best Fitness = 0.8803088803088803, Best Individual = [49.06892844654687, 0.5502450691821166]\n",
            "Generation 8: Best Fitness = 0.8803088803088803, Best Individual = [46.564132700229294, 0.6016735722165751]\n",
            "Generation 9: Best Fitness = 0.8803088803088803, Best Individual = [44.059336953911725, 0.6531020752510337]\n",
            "Generation 10: Best Fitness = 0.8841698841698842, Best Individual = [43.9350179992021, 0.399223110042267]\n",
            "Generation 11: Best Fitness = 0.8803088803088803, Best Individual = [42.80693908075294, 0.678816326768263]\n",
            "Generation 12: Best Fitness = 0.8803088803088803, Best Individual = [41.492381730239345, 0.7201526129009819]\n",
            "Generation 13: Best Fitness = 0.8803088803088803, Best Individual = [41.52346146891675, 0.7123415955932371]\n",
            "Generation 14: Best Fitness = 0.8803088803088803, Best Individual = [22.796231444410772, 0.7187701584725443]\n",
            "Generation 15: Best Fitness = 0.8803088803088803, Best Individual = [41.52346146891675, 0.7123415955932371]\n",
            "Generation 16: Best Fitness = 0.8803088803088803, Best Individual = [41.47669798080591, 0.7195780209174705]\n",
            "Generation 17: Best Fitness = 0.8803088803088803, Best Individual = [39.36479137795793, 0.7170247348631056]\n",
            "Generation 18: Best Fitness = 0.8803088803088803, Best Individual = [41.68414796056204, 0.715991113105537]\n",
            "Generation 19: Best Fitness = 0.8803088803088803, Best Individual = [40.61650378711035, 0.7165235764094129]\n",
            "Generation 20: Best Fitness = 0.8803088803088803, Best Individual = [38.9948203329602, 0.7208103892225111]\n",
            "Generation 21: Best Fitness = 0.8803088803088803, Best Individual = [38.9948203329602, 0.7208103892225111]\n",
            "Generation 22: Best Fitness = 0.8957528957528957, Best Individual = [39.23997786101981, 0.35959715854711943]\n",
            "Generation 23: Best Fitness = 0.8803088803088803, Best Individual = [38.9948203329602, 0.7208103892225111]\n",
            "Generation 24: Best Fitness = 0.8803088803088803, Best Individual = [41.08517976534907, 0.7231336238792209]\n",
            "Generation 25: Best Fitness = 0.8803088803088803, Best Individual = [39.158258684999936, 0.7186875106451531]\n",
            "Generation 26: Best Fitness = 0.8803088803088803, Best Individual = [39.158258684999936, 0.7186875106451531]\n",
            "Generation 27: Best Fitness = 0.8803088803088803, Best Individual = [37.92253213895004, 0.7204724283173192]\n",
            "Generation 28: Best Fitness = 0.8803088803088803, Best Individual = [39.25611526200881, 0.7211007935545999]\n",
            "Generation 29: Best Fitness = 0.8957528957528957, Best Individual = [37.92253213895004, 0.2856432907815033]\n",
            "Generation 30: Best Fitness = 0.8803088803088803, Best Individual = [39.25611526200881, 0.7211007935545999]\n",
            "Generation 31: Best Fitness = 0.8803088803088803, Best Individual = [39.25611526200881, 0.7211007935545999]\n",
            "Generation 32: Best Fitness = 0.8996138996138996, Best Individual = [39.19079152974666, 0.231197894198898]\n",
            "Generation 33: Best Fitness = 0.8996138996138996, Best Individual = [39.19079152974666, 0.231197894198898]\n",
            "Generation 34: Best Fitness = 0.8803088803088803, Best Individual = [38.83937053605294, 0.6530870485747401]\n",
            "Generation 35: Best Fitness = 0.8803088803088803, Best Individual = [80.5463274360579, 0.6869761025826799]\n",
            "Generation 36: Best Fitness = 0.8803088803088803, Best Individual = [38.88555131188079, 0.5815038139887194]\n",
            "Generation 37: Best Fitness = 0.8803088803088803, Best Individual = [70.11958821105665, 0.678503839080695]\n",
            "Generation 38: Best Fitness = 0.8803088803088803, Best Individual = [54.437804900959215, 0.6996844978356573]\n",
            "Generation 39: Best Fitness = 0.8803088803088803, Best Individual = [54.437804900959215, 0.6996844978356573]\n",
            "Generation 40: Best Fitness = 0.8996138996138996, Best Individual = [59.67940482080085, 0.2629674977265861]\n",
            "Generation 41: Best Fitness = 0.8803088803088803, Best Individual = [63.58640648307063, 0.67139375073153]\n",
            "Generation 42: Best Fitness = 0.8803088803088803, Best Individual = [58.372365882154085, 0.679109141103337]\n",
            "Generation 43: Best Fitness = 0.8803088803088803, Best Individual = [59.02588535147747, 0.6762346933014136]\n",
            "Generation 44: Best Fitness = 0.8803088803088803, Best Individual = [59.66596065554628, 0.6766889154202705]\n",
            "Generation 45: Best Fitness = 0.8803088803088803, Best Individual = [59.83757537905724, 0.47595982033433804]\n",
            "Generation 46: Best Fitness = 0.8957528957528957, Best Individual = [59.97658346318778, 0.3447354470134967]\n",
            "Generation 47: Best Fitness = 0.8957528957528957, Best Individual = [59.97658346318778, 0.3447354470134967]\n",
            "Generation 48: Best Fitness = 0.8957528957528957, Best Individual = [59.97658346318778, 0.3447354470134967]\n",
            "Generation 49: Best Fitness = 0.8957528957528957, Best Individual = [59.97658346318778, 0.3447354470134967]\n",
            "Best hyperparameters: C=59.97658346318778, gamma=0.3447354470134967\n",
            "Best validation accuracy: 0.8957528957528957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_full = X.iloc[:1468]\n",
        "y_train_full = y.iloc[:1468]\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "best_model = SVC(C=best_params[0], gamma=best_params[1])\n",
        "best_model.fit(X_train_full, y_train_full)  # Train on the full training set\n",
        "y_test_pred = best_model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print(f'Test accuracy with best hyperparameters: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kV514ZJM-Z0S",
        "outputId": "44e70ef3-7b6b-44cb-c6c8-a6cba2ad99a1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy with best hyperparameters: 0.8846153846153846\n"
          ]
        }
      ]
    }
  ]
}