{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Car Dataset**"
      ],
      "metadata": {
        "id": "maX0EJntW9RB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sUlioD9GwgI",
        "outputId": "d7d13bf0-08db-4b36-fefa-0b4989ae2066"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     buying  maint  doors persons lug_boot safety  class\n",
            "0     vhigh  vhigh      2       2    small    low  unacc\n",
            "1     vhigh  vhigh      2       2    small    med  unacc\n",
            "2     vhigh  vhigh      2       2    small   high  unacc\n",
            "3     vhigh  vhigh      2       2      med    low  unacc\n",
            "4     vhigh  vhigh      2       2      med    med  unacc\n",
            "...     ...    ...    ...     ...      ...    ...    ...\n",
            "1723    low    low  5more    more      med    med   good\n",
            "1724    low    low  5more    more      med   high  vgood\n",
            "1725    low    low  5more    more      big    low  unacc\n",
            "1726    low    low  5more    more      big    med   good\n",
            "1727    low    low  5more    more      big   high  vgood\n",
            "\n",
            "[1728 rows x 7 columns]\n",
            "\n",
            "Checking NULL values:\n",
            " buying      0\n",
            "maint       0\n",
            "doors       0\n",
            "persons     0\n",
            "lug_boot    0\n",
            "safety      0\n",
            "class       0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#include libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#load data and checking contents\n",
        "data = pd.read_csv(\"car.data.csv\")\n",
        "print(data)\n",
        "\n",
        "#check for null values\n",
        "print(\"\\nChecking NULL values:\\n\",data.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing data\n",
        "categorical_cols = data.select_dtypes(include=['object']).columns.tolist()\n",
        "print(\"Categorical Columns:\", categorical_cols)\n",
        "print(\"\\n\")\n",
        "\n",
        "#label encoding features\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "labelEncoder = LabelEncoder()\n",
        "\n",
        "for col in categorical_cols:\n",
        "  data[col] = labelEncoder.fit_transform(data[col])\n",
        "\n",
        "print(data)"
      ],
      "metadata": {
        "id": "b_Z5-eI0MOBw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2fce788-a806-4899-a2d1-019d85d059ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categorical Columns: ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']\n",
            "\n",
            "\n",
            "      buying  maint  doors  persons  lug_boot  safety  class\n",
            "0          3      3      0        0         2       1      2\n",
            "1          3      3      0        0         2       2      2\n",
            "2          3      3      0        0         2       0      2\n",
            "3          3      3      0        0         1       1      2\n",
            "4          3      3      0        0         1       2      2\n",
            "...      ...    ...    ...      ...       ...     ...    ...\n",
            "1723       1      1      3        2         1       2      1\n",
            "1724       1      1      3        2         1       0      3\n",
            "1725       1      1      3        2         0       1      2\n",
            "1726       1      1      3        2         0       2      1\n",
            "1727       1      1      3        2         0       0      3\n",
            "\n",
            "[1728 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#selecting target variable and features\n",
        "X = data.drop('class', axis = 1)\n",
        "y = data['class']\n",
        "\n",
        "#splitting data for training, validating and testing\n",
        "X_train = X.iloc[:1209]\n",
        "X_validation = X.iloc[1209:1468]\n",
        "X_test = X.iloc[1468:]\n",
        "print(X_validation)\n",
        "y_train = y.iloc[:1209]\n",
        "y_validation = y.iloc[1209:1468]\n",
        "y_test = y.iloc[1468:]"
      ],
      "metadata": {
        "id": "jYcVCLkX0Q5g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac8e0b67-3cd6-4a22-c49f-4e2c6ea5510b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      buying  maint  doors  persons  lug_boot  safety\n",
            "1209       2      1      0        2         1       1\n",
            "1210       2      1      0        2         1       2\n",
            "1211       2      1      0        2         1       0\n",
            "1212       2      1      0        2         0       1\n",
            "1213       2      1      0        2         0       2\n",
            "...      ...    ...    ...      ...       ...     ...\n",
            "1463       1      0      2        0         1       0\n",
            "1464       1      0      2        0         0       1\n",
            "1465       1      0      2        0         0       2\n",
            "1466       1      0      2        0         0       0\n",
            "1467       1      0      2        1         2       1\n",
            "\n",
            "[259 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Evaluation Metrics**"
      ],
      "metadata": {
        "id": "OXcnxl9Y7rsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy\n",
        "def calc_accuracy(y_true, y_pred):\n",
        "  correct = 0\n",
        "  total = len(y_true)\n",
        "\n",
        "  for true_label, predicted_label in zip(y_true, y_pred):\n",
        "    if true_label == predicted_label:\n",
        "      correct += 1\n",
        "\n",
        "  accuracy = correct / total\n",
        "  return accuracy\n",
        "\n",
        "#Confusion Matrix\n",
        "def confusion_matrix(y_true, y_pred):\n",
        "  TN, TP, FN, FP = 0, 0, 0, 0\n",
        "\n",
        "  for true_label, predicted_label in zip(y_true, y_pred):\n",
        "    if true_label == 0 and predicted_label == 0:\n",
        "      TN += 1\n",
        "    elif true_label == 0 and predicted_label == 1:\n",
        "      FP += 1\n",
        "    elif true_label == 1 and predicted_label == 0:\n",
        "      FN += 1\n",
        "    elif true_label == 1 and predicted_label == 1:\n",
        "      TP += 1\n",
        "\n",
        "  return (TN, TP, FN, FP)\n",
        "\n",
        "#Average Precision\n",
        "def avg_precision(y_true, y_pred):\n",
        "  data = list(zip(y_true, y_pred))\n",
        "  data.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "  # Initialize variables\n",
        "  num_positives = sum(y_true)\n",
        "  num_examples = len(y_true)\n",
        "  true_positives = 0\n",
        "  precision_sum = 0\n",
        "  recall_sum = 0\n",
        "\n",
        "  # Calculate precision and recall at each threshold\n",
        "  for i in range(num_examples):\n",
        "    if data[i][0] == 1:\n",
        "      true_positives += 1\n",
        "      precision = true_positives / (i + 1)\n",
        "      recall = true_positives / num_positives\n",
        "      precision_sum += precision\n",
        "      recall_sum += recall\n",
        "\n",
        "  # Calculate Average Precision (AP) using the precision-recall curve\n",
        "  if num_positives == 0:\n",
        "    average_precision = 0\n",
        "  else:\n",
        "    average_precision = precision_sum / num_positives\n",
        "\n",
        "  return average_precision\n",
        "\n",
        "\n",
        "#Average Recall\n",
        "def avg_recall(y_true, y_pred):\n",
        "  total_positives = sum(y_true)  # Total number of positive samples\n",
        "  thresholds = sorted(set(y_pred), reverse=True)  # Unique sorted thresholds\n",
        "\n",
        "  recall_values = []\n",
        "  for threshold in thresholds:\n",
        "    y_pred_thresholded = [1 if pred >= threshold else 0 for pred in y_pred]\n",
        "    true_positives = sum([1 for true, pred in zip(y_true, y_pred_thresholded) if true == 1 and pred == 1])\n",
        "    recall = true_positives / total_positives\n",
        "    recall_values.append(recall)\n",
        "\n",
        "  average_recall = sum(recall_values) / len(recall_values)\n",
        "\n",
        "  return average_recall\n",
        "\n",
        "#Average F1-Score\n",
        "def avg_f1(y_true, y_pred):\n",
        "  total_positives = sum(y_true)  # Total number of positive samples\n",
        "  thresholds = sorted(set(y_pred), reverse=True)  # Unique sorted thresholds\n",
        "\n",
        "  f1_scores = []\n",
        "  for threshold in thresholds:\n",
        "    y_pred_thresholded = [1 if pred >= threshold else 0 for pred in y_pred]\n",
        "\n",
        "  # Calculate precision and recall\n",
        "  true_positives = sum([1 for true, pred in zip(y_true, y_pred_thresholded) if true == 1 and pred == 1])\n",
        "  predicted_positives = sum(y_pred_thresholded)\n",
        "\n",
        "  if predicted_positives == 0:\n",
        "    precision = 0.0\n",
        "  else:\n",
        "    precision = true_positives / predicted_positives\n",
        "\n",
        "  recall = true_positives / total_positives\n",
        "\n",
        "  # Calculate F1-score\n",
        "  if precision + recall == 0:\n",
        "    f1 = 0.0\n",
        "  else:\n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "  f1_scores.append(f1)\n",
        "\n",
        "  average_f1_score = sum(f1_scores) / len(f1_scores)\n",
        "\n",
        "  return average_f1_score"
      ],
      "metadata": {
        "id": "lqrd9wOM7oCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Decision Tree**"
      ],
      "metadata": {
        "id": "7OPFshp2eqm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the dataset\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "#Define the Decision Tree Classifier\n",
        "dt_classifier = DecisionTreeClassifier()\n",
        "\n",
        "dt = dt_classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "fgMe3Hu1k5lU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Validating the model using validation set\n",
        "y_pred = dt.predict(X_validation)\n",
        "\n",
        "acc = calc_accuracy(y_validation, y_pred)\n",
        "print(\"Accuracy: \", acc)\n",
        "ap = avg_precision(y_validation, y_pred)\n",
        "print(\"Average Precision: \", ap)\n",
        "ar = avg_recall(y_validation, y_pred)\n",
        "print(\"Average Recall: \", ar)\n",
        "af = avg_f1(y_validation, y_pred)\n",
        "print(\"Average F1-Score: \", af)\n",
        "TN, TP, FN, FP = confusion_matrix(y_validation, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(f\"TN: {TN}   FP: {FP}\")\n",
        "print(f\"FN: {FN}   TP: {TP}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytUYXUVEvFJr",
        "outputId": "0d50b247-55eb-4936-ff3a-e1e5b1260bf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.752895752895753\n",
            "Average Precision:  0.0022793963841093528\n",
            "Average Recall:  0.015903307888040712\n",
            "Average F1-Score:  0.06134969325153374\n",
            "Confusion Matrix:\n",
            "TN: 18   FP: 0\n",
            "FN: 15   TP: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Validating\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the hyperparameter grid for grid search\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV with cross-validation (e.g., 5-fold)\n",
        "grid_search = GridSearchCV(estimator=dt_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit GridSearchCV on the combined training and validation sets\n",
        "X_train_new = X.iloc[:1468]\n",
        "y_train_new = y.iloc[:1468]\n",
        "grid_search.fit(X_train_new, y_train_new)\n",
        "\n",
        "# Get the best model on the test set\n",
        "best_dt_model = grid_search.best_estimator_\n",
        "\n",
        "print(best_dt_model)"
      ],
      "metadata": {
        "id": "u4bIEhRjdsni",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71c12465-807c-4205-c418-253a27dadc32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeClassifier(max_depth=7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing best model using test set\n",
        "y_pred = best_dt_model.predict(X_test)\n",
        "\n",
        "acc = calc_accuracy(y_test, y_pred)\n",
        "print(\"Accuracy: \", acc)\n",
        "ap = avg_precision(y_test, y_pred)\n",
        "print(\"Average Precision: \", ap)\n",
        "ar = avg_recall(y_test, y_pred)\n",
        "print(\"Average Recall: \", ar)\n",
        "af = avg_f1(y_test, y_pred)\n",
        "print(\"Average F1-Score: \", af)\n",
        "TN, TP, FN, FP = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(f\"TN: {TN}   FP: {FP}\")\n",
        "print(f\"FN: {FN}   TP: {TP}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ta0gKedI8ZiR",
        "outputId": "9bd85ba0-e550-4a36-9f61-966accd49d09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.7769230769230769\n",
            "Average Precision:  0.017221224472013914\n",
            "Average Recall:  0.04434250764525994\n",
            "Average F1-Score:  0.13218390804597702\n",
            "Confusion Matrix:\n",
            "TN: 36   FP: 0\n",
            "FN: 40   TP: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **XGB Classifier**"
      ],
      "metadata": {
        "id": "QmfcAVZ1wlLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the dataset\n",
        "import xgboost as xgb\n",
        "\n",
        "#Define the XGBClassifier\n",
        "xgb_classifier = xgb.XGBClassifier(objective='multi:softmax', num_class=3, random_state=42)\n",
        "\n",
        "xgbc = xgb_classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "ju4CG-JVwpV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Validating the model using validation set\n",
        "y_pred = xgbc.predict(X_validation)\n",
        "\n",
        "acc = calc_accuracy(y_validation, y_pred)\n",
        "print(\"Accuracy: \", acc)\n",
        "ap = avg_precision(y_validation, y_pred)\n",
        "print(\"Average Precision: \", ap)\n",
        "ar = avg_recall(y_validation, y_pred)\n",
        "print(\"Average Recall: \", ar)\n",
        "af = avg_f1(y_validation, y_pred)\n",
        "print(\"Average F1-Score: \", af)\n",
        "TN, TP, FN, FP = confusion_matrix(y_validation, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(f\"TN: {TN}   FP: {FP}\")\n",
        "print(f\"FN: {FN}   TP: {TP}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62WQWdVCGBDH",
        "outputId": "96264b81-80b0-491f-f4f9-5e0c9181eac8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.7374517374517374\n",
            "Average Precision:  0.0022786012242673767\n",
            "Average Recall:  0.016963528413910092\n",
            "Average F1-Score:  0.06134969325153374\n",
            "Confusion Matrix:\n",
            "TN: 19   FP: 0\n",
            "FN: 20   TP: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Validating\n",
        "#Define the hyperparameter grid for grid searching\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.1, 0.01, 0.001],\n",
        "    'n_estimators': [100, 200, 300]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, cv=3, scoring='accuracy')\n",
        "grid_search.fit(X_train_new, y_train_new)\n",
        "\n",
        "# Get the best XGBClassifier model from GridSearchCV\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "\n",
        "print(best_xgb_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0Hh_5MZGOj0",
        "outputId": "f2f4f4ca-9a19-4be1-d79e-620b60797365"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
            "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
            "              gamma=None, grow_policy=None, importance_type=None,\n",
            "              interaction_constraints=None, learning_rate=0.001, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
            "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
            "              multi_strategy=None, n_estimators=300, n_jobs=None, num_class=3,\n",
            "              num_parallel_tree=None, ...)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing best model using test set\n",
        "y_pred = best_xgb_model.predict(X_test)\n",
        "\n",
        "acc = calc_accuracy(y_test, y_pred)\n",
        "print(\"Accuracy: \", acc)\n",
        "ap = avg_precision(y_test, y_pred)\n",
        "print(\"Average Precision: \", ap)\n",
        "ar = avg_recall(y_test, y_pred)\n",
        "print(\"Average Recall: \", ar)\n",
        "af = avg_f1(y_test, y_pred)\n",
        "print(\"Average F1-Score: \", af)\n",
        "TN, TP, FN, FP = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(f\"TN: {TN}   FP: {FP}\")\n",
        "print(f\"FN: {FN}   TP: {TP}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m694tLwhGyS6",
        "outputId": "80c4fe55-b7f5-4492-841f-4ad54c4a454b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.6153846153846154\n",
            "Average Precision:  0.010691224374171587\n",
            "Average Recall:  0.052752293577981654\n",
            "Average F1-Score:  0.13218390804597702\n",
            "Confusion Matrix:\n",
            "TN: 18   FP: 0\n",
            "FN: 46   TP: 0\n"
          ]
        }
      ]
    }
  ]
}